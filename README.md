# ML-Linear-Reg-Bin-Class
Implement logistic regression from scratch for binary classification


Make a semilogy plot of the cost function value L(beta) versus iteration of gradient descent. Do you observe that the value of L(beta) is decreasing at each iteration? Also make a scatter plot of the data that includes the optimal decision boundary, as we did in class. Compare your decision boundary with the result obtained by using scikit-learn's implementation of logistic regression:  Do the two results agree? (Documentation for scikit-learn's logistic regression implementation can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html (Links to an external site.))

Also use your code to make an attempt on this Kaggle fraud detection challenge: https://www.kaggle.com/c/ieee-fraud-detection/data
